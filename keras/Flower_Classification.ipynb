{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Flower Classification-Android.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwyQTJiem2Ry",
        "colab_type": "text"
      },
      "source": [
        "# Flower Classification\n",
        "\n",
        "This model classifies two type of flowers -  Rose and Sunflower. You can add  classes or  make changes in the model as per your requirement. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNrUODRonpv5",
        "colab_type": "text"
      },
      "source": [
        "## Import required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3L5uVZsnRQK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os, cv2, math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import imagenet_utils\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "import itertools\n",
        "from tqdm import tqdm\n",
        "from shutil import copyfile\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyA5ewGHnxmy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Path for the dataset\n",
        "DATASET_PATH = '/content/gdrive/My Drive/FlowerDataset'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwCllprurzm5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Splitting the data into train and valid data\n",
        "\n",
        "train_set = {}\n",
        "valid_set = {}\n",
        "\n",
        "for path in os.listdir(DATASET_PATH):\n",
        "  path_dir = os.path.join(DATASET_PATH, path) # e.g. DATASET_PATH/'0'\n",
        "  path_files = os.listdir(path_dir)\n",
        "  # Training set's size is 80% of the data\n",
        "  train_list , test_list = train_test_split(path_files, test_size = 0.2)\n",
        "  \n",
        "  train_set[path] = train_list\n",
        "  valid_set[path] = validation_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uN-0mIj6olJX",
        "colab_type": "text"
      },
      "source": [
        "## For Training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W06F0BljohqI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9e900f6e-d1a3-4b92-bbd7-625961f06648"
      },
      "source": [
        "for path in tqdm(train_set.keys()):\n",
        "  path_dir = os.path.join(DATASET_PATH, 'training_set', 'class_0' + str(path))\n",
        "  os.makedirs(path_dir)\n",
        "  for file in train_set[path]:\n",
        "    # src path is DATASET_PATH/'0'/file\n",
        "    src = os.path.join(DATASET_PATH, path, file)\n",
        "    # dest path is DATASET_PATH/'training_set'/'class_00'\n",
        "    # to accomodate for the directory format required by flow_from_directory method in keras\n",
        "    dest = os.path.join(path_dir, file)\n",
        "    copyfile(src, dest)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:59<00:00, 29.74s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0TBxc8wo1-O",
        "colab_type": "text"
      },
      "source": [
        "## For validation Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ks5pIsaIooQN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4974b867-c460-4532-a7bc-1efda3fabc6d"
      },
      "source": [
        "for path in tqdm(valid_set.keys()):\n",
        "  path_dir = os.path.join(DATASET_PATH, 'validation_set', 'class_0' + str(path))\n",
        "  os.makedirs(path_dir)\n",
        "  for file in valid_set[path]:\n",
        "    # src path is DATASET_PATH/'0'/file\n",
        "    src = os.path.join(DATASET_PATH, path, file)\n",
        "    # dest path is DATASET_PATH/'training_set'/'class_00'\n",
        "    # to accomodate for the directory format required by flow_from_directory method in keras\n",
        "    dest = os.path.join(path_dir, file)\n",
        "    copyfile(src, dest)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:13<00:00,  6.61s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRmlnEAfpEdY",
        "colab_type": "text"
      },
      "source": [
        "## Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vT-3YNZ-pGUo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "cc57d39d-eccb-4ba6-f0a5-37468545294e"
      },
      "source": [
        "#For training data\n",
        "train_datagen = ImageDataGenerator(rescale = 1.0/255.0, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n",
        "\n",
        "#For validation data, we only rescale the pictures\n",
        "valid_datagen = ImageDataGenerator(rescale = 1.0/255.0)\n",
        "\n",
        "\n",
        "train_batches = train_datagen.flow_from_directory(os.path.join(DATASET_PATH, 'training_set'), target_size = (64, 64), batch_size = 32, shuffle = True)\n",
        "valid_batches = valid_datagen.flow_from_directory(os.path.join(DATASET_PATH, 'validation_set'), target_size = (64, 64), batch_size = 32, shuffle = True)\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 345 images belonging to 2 classes.\n",
            "Found 74 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cj0-uZSOqVBB",
        "colab_type": "text"
      },
      "source": [
        "## Build and Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXz_xfa8qLI8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model():\n",
        "\n",
        "    model = Sequential()\n",
        "    \n",
        "    #Input Layer\n",
        "    model.add(Conv2D(filters=32, kernel_size=3, padding='same', activation='relu', input_shape=(64,64,3)))\n",
        "    model.add(MaxPooling2D(pool_size=2))\n",
        "    model.add(Dropout(0.3))\n",
        "    \n",
        "    #Adding convolutional layer\n",
        "    Conv2D(filters=128, kernel_size=3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(pool_size=2),\n",
        "    Dropout(0.3),\n",
        "    \n",
        "    #Flattening before the fully-connected network\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    \n",
        "    #Final Output Layer\n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "  \n",
        "   #Compile the model\n",
        "    model.compile(loss= 'categorical_crossentropy',\n",
        "         optimizer=tf.keras.optimizers.Adam(),\n",
        "         metrics=['accuracy'])\n",
        "      \n",
        "    return model\n",
        "\n",
        "model = create_model()\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rT6vXbVJfyK3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f5f492f8-d4eb-47aa-dc2b-71df20e5e5da"
      },
      "source": [
        "model.fit_generator(train_batches, \n",
        "                    steps_per_epoch = math.ceil(train_batches.n / train_batches.batch_size),\n",
        "                    validation_data = valid_batches,\n",
        "                    validation_steps = math.ceil(valid_batches.n / valid_batches.batch_size), epochs = 30)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-11-cbff24df233d>:4: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/30\n",
            "11/11 [==============================] - 3s 300ms/step - loss: 0.7043 - accuracy: 0.5681 - val_loss: 0.5364 - val_accuracy: 0.8243\n",
            "Epoch 2/30\n",
            "11/11 [==============================] - 3s 295ms/step - loss: 0.5343 - accuracy: 0.7594 - val_loss: 0.4213 - val_accuracy: 0.8378\n",
            "Epoch 3/30\n",
            "11/11 [==============================] - 3s 284ms/step - loss: 0.4218 - accuracy: 0.8377 - val_loss: 0.3351 - val_accuracy: 0.8784\n",
            "Epoch 4/30\n",
            "11/11 [==============================] - 3s 284ms/step - loss: 0.3663 - accuracy: 0.8435 - val_loss: 0.2837 - val_accuracy: 0.8919\n",
            "Epoch 5/30\n",
            "11/11 [==============================] - 3s 290ms/step - loss: 0.3549 - accuracy: 0.8609 - val_loss: 0.2328 - val_accuracy: 0.9189\n",
            "Epoch 6/30\n",
            "11/11 [==============================] - 3s 289ms/step - loss: 0.2916 - accuracy: 0.8870 - val_loss: 0.2435 - val_accuracy: 0.8919\n",
            "Epoch 7/30\n",
            "11/11 [==============================] - 3s 285ms/step - loss: 0.2833 - accuracy: 0.8928 - val_loss: 0.2108 - val_accuracy: 0.9189\n",
            "Epoch 8/30\n",
            "11/11 [==============================] - 3s 284ms/step - loss: 0.2715 - accuracy: 0.8841 - val_loss: 0.2806 - val_accuracy: 0.8514\n",
            "Epoch 9/30\n",
            "11/11 [==============================] - 3s 289ms/step - loss: 0.2768 - accuracy: 0.8783 - val_loss: 0.2197 - val_accuracy: 0.8919\n",
            "Epoch 10/30\n",
            "11/11 [==============================] - 3s 286ms/step - loss: 0.2613 - accuracy: 0.8899 - val_loss: 0.1804 - val_accuracy: 0.9459\n",
            "Epoch 11/30\n",
            "11/11 [==============================] - 3s 291ms/step - loss: 0.2009 - accuracy: 0.9130 - val_loss: 0.1576 - val_accuracy: 0.9459\n",
            "Epoch 12/30\n",
            "11/11 [==============================] - 3s 290ms/step - loss: 0.2124 - accuracy: 0.9246 - val_loss: 0.1517 - val_accuracy: 0.9595\n",
            "Epoch 13/30\n",
            "11/11 [==============================] - 3s 285ms/step - loss: 0.2366 - accuracy: 0.9101 - val_loss: 0.2241 - val_accuracy: 0.8649\n",
            "Epoch 14/30\n",
            "11/11 [==============================] - 3s 284ms/step - loss: 0.2082 - accuracy: 0.9072 - val_loss: 0.1517 - val_accuracy: 0.9459\n",
            "Epoch 15/30\n",
            "11/11 [==============================] - 3s 286ms/step - loss: 0.2043 - accuracy: 0.9304 - val_loss: 0.1468 - val_accuracy: 0.9595\n",
            "Epoch 16/30\n",
            "11/11 [==============================] - 3s 287ms/step - loss: 0.1938 - accuracy: 0.9101 - val_loss: 0.1335 - val_accuracy: 0.9595\n",
            "Epoch 17/30\n",
            "11/11 [==============================] - 3s 285ms/step - loss: 0.2003 - accuracy: 0.9043 - val_loss: 0.1370 - val_accuracy: 0.9595\n",
            "Epoch 18/30\n",
            "11/11 [==============================] - 3s 286ms/step - loss: 0.1941 - accuracy: 0.9246 - val_loss: 0.1345 - val_accuracy: 0.9595\n",
            "Epoch 19/30\n",
            "11/11 [==============================] - 3s 288ms/step - loss: 0.1837 - accuracy: 0.9304 - val_loss: 0.1437 - val_accuracy: 0.9459\n",
            "Epoch 20/30\n",
            "11/11 [==============================] - 3s 288ms/step - loss: 0.1758 - accuracy: 0.9304 - val_loss: 0.1469 - val_accuracy: 0.9595\n",
            "Epoch 21/30\n",
            "11/11 [==============================] - 3s 293ms/step - loss: 0.1660 - accuracy: 0.9362 - val_loss: 0.1349 - val_accuracy: 0.9595\n",
            "Epoch 22/30\n",
            "11/11 [==============================] - 3s 286ms/step - loss: 0.1620 - accuracy: 0.9420 - val_loss: 0.1298 - val_accuracy: 0.9595\n",
            "Epoch 23/30\n",
            "11/11 [==============================] - 3s 288ms/step - loss: 0.1509 - accuracy: 0.9594 - val_loss: 0.1239 - val_accuracy: 0.9595\n",
            "Epoch 24/30\n",
            "11/11 [==============================] - 3s 286ms/step - loss: 0.1479 - accuracy: 0.9449 - val_loss: 0.1378 - val_accuracy: 0.9730\n",
            "Epoch 25/30\n",
            "11/11 [==============================] - 3s 287ms/step - loss: 0.1511 - accuracy: 0.9391 - val_loss: 0.1194 - val_accuracy: 0.9595\n",
            "Epoch 26/30\n",
            "11/11 [==============================] - 3s 288ms/step - loss: 0.1570 - accuracy: 0.9391 - val_loss: 0.1171 - val_accuracy: 0.9595\n",
            "Epoch 27/30\n",
            "11/11 [==============================] - 3s 292ms/step - loss: 0.1543 - accuracy: 0.9449 - val_loss: 0.1300 - val_accuracy: 0.9730\n",
            "Epoch 28/30\n",
            "11/11 [==============================] - 3s 286ms/step - loss: 0.1519 - accuracy: 0.9362 - val_loss: 0.1189 - val_accuracy: 0.9730\n",
            "Epoch 29/30\n",
            "11/11 [==============================] - 3s 283ms/step - loss: 0.1462 - accuracy: 0.9449 - val_loss: 0.1388 - val_accuracy: 0.9324\n",
            "Epoch 30/30\n",
            "11/11 [==============================] - 3s 285ms/step - loss: 0.1522 - accuracy: 0.9478 - val_loss: 0.1350 - val_accuracy: 0.9595\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa993371208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4PNhAMbM9K8",
        "colab_type": "text"
      },
      "source": [
        "## Saving Convolutional model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxF18lXOSqYu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tensorflow_keras_file = \"flower.h5\"\n",
        "tf.keras.models.save_model(model, tensorflow_keras_file)\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pDSIv_9NMi8",
        "colab_type": "text"
      },
      "source": [
        "## Converting .h5 model  into .tflite file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81UZ1g3cWsvm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a162a969-129d-4fab-b4c8-c5f6d528542a"
      },
      "source": [
        "model = tf.keras.models.load_model(\"flower.h5\")\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "open(\"flower.tflite\", \"wb\").write(tflite_model)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16784220"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKEgfhi0jVNQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}